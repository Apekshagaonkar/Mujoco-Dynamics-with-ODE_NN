{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEK6fR6Fucu8",
        "outputId": "c269a1ea-ad60-4914-926b-566ed94d5e43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Latent_ODE_ECE_228'...\n",
            "remote: Enumerating objects: 2031, done.\u001b[K\n",
            "remote: Counting objects: 100% (32/32), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 2031 (delta 13), reused 21 (delta 7), pack-reused 1999\u001b[K\n",
            "Receiving objects: 100% (2031/2031), 55.00 MiB | 14.02 MiB/s, done.\n",
            "Resolving deltas: 100% (1696/1696), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/akucsd/Latent_ODE_ECE_228.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ! git clone https://github.com/openai/gym.git\n",
        "# !pip install -e /content/gym\n",
        "!pip install gym==0.22\n",
        "!pip install free-mujoco-py\n",
        "!pip install moviepy==1.0.0\n",
        "# !pip install tensorboard==2.3.0 tensorboardX==1.8 matplotlib ipython==6.4.0 moviepy==1.0.0 pyvirtualdisplay==1.3.2\n",
        "!pip install torch\n",
        "!pip install mujoco\n",
        "# !pip install opencv-python==4.4.0.42\n",
        "!pip install ipdb==0.13.3\n",
        "!pip install ray\n",
        "!pip install tqdm\n",
        "! pip install pyvirtualdisplay"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AvKPYIVKykm",
        "outputId": "74a50c35-102b-488e-c73e-3b4be7446cb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gym==0.22\n",
            "  Downloading gym-0.22.0.tar.gz (631 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/631.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.0/631.1 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m631.1/631.1 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym==0.22) (1.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym==0.22) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym==0.22) (0.0.8)\n",
            "Building wheels for collected packages: gym\n",
            "  Building wheel for gym (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.22.0-py3-none-any.whl size=708362 sha256=978913fae7f1a59351192cc9d01a26eff7a39f30c42fe146ac699ca8dddb34f9\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/e8/e8/6dfbc92a1dcd76c1a5e2bb982750fd6b7e792239f46039e6b1\n",
            "Successfully built gym\n",
            "Installing collected packages: gym\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.25.2\n",
            "    Uninstalling gym-0.25.2:\n",
            "      Successfully uninstalled gym-0.25.2\n",
            "Successfully installed gym-0.22.0\n",
            "Collecting free-mujoco-py\n",
            "  Downloading free_mujoco_py-2.1.6-py3-none-any.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m76.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Cython<0.30.0,>=0.29.24 (from free-mujoco-py)\n",
            "  Downloading Cython-0.29.37-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cffi<2.0.0,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from free-mujoco-py) (1.16.0)\n",
            "Collecting fasteners==0.15 (from free-mujoco-py)\n",
            "  Downloading fasteners-0.15-py2.py3-none-any.whl (23 kB)\n",
            "Collecting glfw<2.0.0,>=1.4.0 (from free-mujoco-py)\n",
            "  Downloading glfw-1.12.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38-none-manylinux2014_x86_64.whl (203 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.7/203.7 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: imageio<3.0.0,>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from free-mujoco-py) (2.31.6)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.21.3 in /usr/local/lib/python3.10/dist-packages (from free-mujoco-py) (1.25.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fasteners==0.15->free-mujoco-py) (1.16.0)\n",
            "Collecting monotonic>=0.1 (from fasteners==0.15->free-mujoco-py)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi<2.0.0,>=1.15.0->free-mujoco-py) (2.22)\n",
            "Requirement already satisfied: pillow<10.1.0,>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0.0,>=2.9.0->free-mujoco-py) (9.4.0)\n",
            "Installing collected packages: monotonic, glfw, fasteners, Cython, free-mujoco-py\n",
            "  Attempting uninstall: Cython\n",
            "    Found existing installation: Cython 3.0.10\n",
            "    Uninstalling Cython-3.0.10:\n",
            "      Successfully uninstalled Cython-3.0.10\n",
            "Successfully installed Cython-0.29.37 fasteners-0.15 free-mujoco-py-2.1.6 glfw-1.12.0 monotonic-1.6\n",
            "Collecting moviepy==1.0.0\n",
            "  Downloading moviepy-1.0.0.tar.gz (398 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m398.8/398.8 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy==1.0.0) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy==1.0.0) (4.66.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from moviepy==1.0.0) (1.25.2)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy==1.0.0) (2.31.0)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy==1.0.0) (0.1.10)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy==1.0.0) (2.31.6)\n",
            "Requirement already satisfied: imageio_ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy==1.0.0) (0.5.1)\n",
            "Requirement already satisfied: pillow<10.1.0,>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy==1.0.0) (9.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio_ffmpeg>=0.2.0->moviepy==1.0.0) (67.7.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy==1.0.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy==1.0.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy==1.0.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy==1.0.0) (2024.6.2)\n",
            "Building wheels for collected packages: moviepy\n",
            "  Building wheel for moviepy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for moviepy: filename=moviepy-1.0.0-py3-none-any.whl size=131365 sha256=f768749ac7b4d108544dd96ce452a002d2820e95e47366b9c20fb2a772bcb2d9\n",
            "  Stored in directory: /root/.cache/pip/wheels/53/02/b3/1ed75c9098aab405e60ac42176454ba1aacebd9dde2af0a4e1\n",
            "Successfully built moviepy\n",
            "Installing collected packages: moviepy\n",
            "  Attempting uninstall: moviepy\n",
            "    Found existing installation: moviepy 1.0.3\n",
            "    Uninstalling moviepy-1.0.3:\n",
            "      Successfully uninstalled moviepy-1.0.3\n",
            "Successfully installed moviepy-1.0.0\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n",
            "Collecting mujoco\n",
            "  Downloading mujoco-3.1.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mujoco) (1.4.0)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.10/dist-packages (from mujoco) (1.7.0)\n",
            "Requirement already satisfied: glfw in /usr/local/lib/python3.10/dist-packages (from mujoco) (1.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mujoco) (1.25.2)\n",
            "Requirement already satisfied: pyopengl in /usr/local/lib/python3.10/dist-packages (from mujoco) (3.1.7)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[epath]->mujoco) (2023.6.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[epath]->mujoco) (6.4.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from etils[epath]->mujoco) (4.12.1)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[epath]->mujoco) (3.19.1)\n",
            "Installing collected packages: mujoco\n",
            "Successfully installed mujoco-3.1.6\n",
            "Collecting ipdb==0.13.3\n",
            "  Downloading ipdb-0.13.3.tar.gz (14 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from ipdb==0.13.3) (67.7.2)\n",
            "Requirement already satisfied: ipython>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from ipdb==0.13.3) (7.34.0)\n",
            "Collecting jedi>=0.16 (from ipython>=5.1.0->ipdb==0.13.3)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.1.0->ipdb==0.13.3) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.1.0->ipdb==0.13.3) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.1.0->ipdb==0.13.3) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.1.0->ipdb==0.13.3) (3.0.45)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=5.1.0->ipdb==0.13.3) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.1.0->ipdb==0.13.3) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.1.0->ipdb==0.13.3) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.1.0->ipdb==0.13.3) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.1.0->ipdb==0.13.3) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=5.1.0->ipdb==0.13.3) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.1.0->ipdb==0.13.3) (0.2.13)\n",
            "Building wheels for collected packages: ipdb\n",
            "  Building wheel for ipdb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ipdb: filename=ipdb-0.13.3-py3-none-any.whl size=10852 sha256=35ebefef50618e6759584bc568ba3f18657256cab2cfef3a8b40990cbc79953c\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/a0/ff/f5310e4965f14639d03daadc11183850bfe2b2c90a961a8001\n",
            "Successfully built ipdb\n",
            "Installing collected packages: jedi, ipdb\n",
            "Successfully installed ipdb-0.13.3 jedi-0.19.1\n",
            "Collecting ray\n",
            "  Downloading ray-2.23.0-cp310-cp310-manylinux2014_x86_64.whl (65.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.7/65.7 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray) (8.1.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray) (3.14.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray) (4.19.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray) (1.0.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ray) (24.0)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray) (3.20.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from ray) (6.0.1)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ray) (2.31.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (0.18.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (2024.6.2)\n",
            "Installing collected packages: ray\n",
            "Successfully installed ray-2.23.0\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.4)\n",
            "Collecting pyvirtualdisplay\n",
            "  Downloading PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: pyvirtualdisplay\n",
            "Successfully installed pyvirtualdisplay-3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/nslyubaykin/relax_dyna_q_example.git\n",
        "! git clone https://github.com/nslyubaykin/relax.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gPn1k5XMQ8K",
        "outputId": "1d5fe3bf-bece-41c9-a933-ad708af00309"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'relax_dyna_q_example'...\n",
            "remote: Enumerating objects: 96, done.\u001b[K\n",
            "remote: Counting objects: 100% (45/45), done.\u001b[K\n",
            "remote: Compressing objects: 100% (45/45), done.\u001b[K\n",
            "remote: Total 96 (delta 24), reused 4 (delta 0), pack-reused 51\u001b[K\n",
            "Receiving objects: 100% (96/96), 95.76 MiB | 14.29 MiB/s, done.\n",
            "Resolving deltas: 100% (24/24), done.\n",
            "Cloning into 'relax'...\n",
            "remote: Enumerating objects: 535, done.\u001b[K\n",
            "remote: Counting objects: 100% (155/155), done.\u001b[K\n",
            "remote: Compressing objects: 100% (113/113), done.\u001b[K\n",
            "remote: Total 535 (delta 103), reused 79 (delta 42), pack-reused 380\u001b[K\n",
            "Receiving objects: 100% (535/535), 198.21 KiB | 15.25 MiB/s, done.\n",
            "Resolving deltas: 100% (333/333), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y \\\n",
        "    libgl1-mesa-dev \\\n",
        "    libgl1-mesa-glx \\\n",
        "    libglew-dev \\\n",
        "    libosmesa6-dev \\\n",
        "    software-properties-common\n",
        "\n",
        "!apt-get install -y patchelf\n",
        "!sudo apt-get install xvfb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvvkkUTYOcSb",
        "outputId": "d09806b3-3d48-4bea-a383-da460a498058"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "software-properties-common is already the newest version (0.99.22.9).\n",
            "The following additional packages will be installed:\n",
            "  libegl-dev libgl-dev libgles-dev libgles1 libglu1-mesa libglu1-mesa-dev libglvnd-core-dev\n",
            "  libglvnd-dev libglx-dev libopengl-dev libosmesa6\n",
            "The following NEW packages will be installed:\n",
            "  libegl-dev libgl-dev libgl1-mesa-dev libgl1-mesa-glx libgles-dev libgles1 libglew-dev\n",
            "  libglu1-mesa libglu1-mesa-dev libglvnd-core-dev libglvnd-dev libglx-dev libopengl-dev libosmesa6\n",
            "  libosmesa6-dev\n",
            "0 upgraded, 15 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 4,020 kB of archives.\n",
            "After this operation, 19.4 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglx-dev amd64 1.4.0-1 [14.1 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgl-dev amd64 1.4.0-1 [101 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libegl-dev amd64 1.4.0-1 [18.0 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libgl1-mesa-glx amd64 23.0.4-0ubuntu1~22.04.1 [5,584 B]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgles1 amd64 1.4.0-1 [11.5 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgles-dev amd64 1.4.0-1 [49.4 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglvnd-core-dev amd64 1.4.0-1 [12.7 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libopengl-dev amd64 1.4.0-1 [3,400 B]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglvnd-dev amd64 1.4.0-1 [3,162 B]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgl1-mesa-dev amd64 23.2.1-1ubuntu3.1~22.04.2 [6,842 B]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglu1-mesa amd64 9.0.2-1 [145 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglu1-mesa-dev amd64 9.0.2-1 [231 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libglew-dev amd64 2.2.0-4 [287 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libosmesa6 amd64 23.2.1-1ubuntu3.1~22.04.2 [3,121 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libosmesa6-dev amd64 23.2.1-1ubuntu3.1~22.04.2 [8,984 B]\n",
            "Fetched 4,020 kB in 2s (1,744 kB/s)\n",
            "Selecting previously unselected package libglx-dev:amd64.\n",
            "(Reading database ... 121918 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libglx-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libglx-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libgl-dev:amd64.\n",
            "Preparing to unpack .../01-libgl-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libgl-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libegl-dev:amd64.\n",
            "Preparing to unpack .../02-libegl-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libegl-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libgl1-mesa-glx:amd64.\n",
            "Preparing to unpack .../03-libgl1-mesa-glx_23.0.4-0ubuntu1~22.04.1_amd64.deb ...\n",
            "Unpacking libgl1-mesa-glx:amd64 (23.0.4-0ubuntu1~22.04.1) ...\n",
            "Selecting previously unselected package libgles1:amd64.\n",
            "Preparing to unpack .../04-libgles1_1.4.0-1_amd64.deb ...\n",
            "Unpacking libgles1:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libgles-dev:amd64.\n",
            "Preparing to unpack .../05-libgles-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libgles-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libglvnd-core-dev:amd64.\n",
            "Preparing to unpack .../06-libglvnd-core-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libglvnd-core-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libopengl-dev:amd64.\n",
            "Preparing to unpack .../07-libopengl-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libopengl-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libglvnd-dev:amd64.\n",
            "Preparing to unpack .../08-libglvnd-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libglvnd-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libgl1-mesa-dev:amd64.\n",
            "Preparing to unpack .../09-libgl1-mesa-dev_23.2.1-1ubuntu3.1~22.04.2_amd64.deb ...\n",
            "Unpacking libgl1-mesa-dev:amd64 (23.2.1-1ubuntu3.1~22.04.2) ...\n",
            "Selecting previously unselected package libglu1-mesa:amd64.\n",
            "Preparing to unpack .../10-libglu1-mesa_9.0.2-1_amd64.deb ...\n",
            "Unpacking libglu1-mesa:amd64 (9.0.2-1) ...\n",
            "Selecting previously unselected package libglu1-mesa-dev:amd64.\n",
            "Preparing to unpack .../11-libglu1-mesa-dev_9.0.2-1_amd64.deb ...\n",
            "Unpacking libglu1-mesa-dev:amd64 (9.0.2-1) ...\n",
            "Selecting previously unselected package libglew-dev:amd64.\n",
            "Preparing to unpack .../12-libglew-dev_2.2.0-4_amd64.deb ...\n",
            "Unpacking libglew-dev:amd64 (2.2.0-4) ...\n",
            "Selecting previously unselected package libosmesa6:amd64.\n",
            "Preparing to unpack .../13-libosmesa6_23.2.1-1ubuntu3.1~22.04.2_amd64.deb ...\n",
            "Unpacking libosmesa6:amd64 (23.2.1-1ubuntu3.1~22.04.2) ...\n",
            "Selecting previously unselected package libosmesa6-dev:amd64.\n",
            "Preparing to unpack .../14-libosmesa6-dev_23.2.1-1ubuntu3.1~22.04.2_amd64.deb ...\n",
            "Unpacking libosmesa6-dev:amd64 (23.2.1-1ubuntu3.1~22.04.2) ...\n",
            "Setting up libglvnd-core-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libgles1:amd64 (1.4.0-1) ...\n",
            "Setting up libgl1-mesa-glx:amd64 (23.0.4-0ubuntu1~22.04.1) ...\n",
            "Setting up libglx-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libglu1-mesa:amd64 (9.0.2-1) ...\n",
            "Setting up libopengl-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libgl-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libosmesa6:amd64 (23.2.1-1ubuntu3.1~22.04.2) ...\n",
            "Setting up libegl-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libglu1-mesa-dev:amd64 (9.0.2-1) ...\n",
            "Setting up libosmesa6-dev:amd64 (23.2.1-1ubuntu3.1~22.04.2) ...\n",
            "Setting up libgles-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libglvnd-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libglew-dev:amd64 (2.2.0-4) ...\n",
            "Setting up libgl1-mesa-dev:amd64 (23.2.1-1ubuntu3.1~22.04.2) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  patchelf\n",
            "0 upgraded, 1 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 72.1 kB of archives.\n",
            "After this operation, 186 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 patchelf amd64 0.14.3-1 [72.1 kB]\n",
            "Fetched 72.1 kB in 1s (60.5 kB/s)\n",
            "Selecting previously unselected package patchelf.\n",
            "(Reading database ... 122058 files and directories currently installed.)\n",
            "Preparing to unpack .../patchelf_0.14.3-1_amd64.deb ...\n",
            "Unpacking patchelf (0.14.3-1) ...\n",
            "Setting up patchelf (0.14.3-1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libfontenc1 libxfont2 libxkbfile1 x11-xkb-utils xfonts-base xfonts-encodings\n",
            "  xfonts-utils xserver-common\n",
            "The following NEW packages will be installed:\n",
            "  libfontenc1 libxfont2 libxkbfile1 x11-xkb-utils xfonts-base xfonts-encodings\n",
            "  xfonts-utils xserver-common xvfb\n",
            "0 upgraded, 9 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 7,813 kB of archives.\n",
            "After this operation, 11.9 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfontenc1 amd64 1:1.1.4-1build3 [14.7 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxfont2 amd64 1:2.0.5-1build1 [94.5 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbfile1 amd64 1:1.1.0-1build3 [71.8 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-xkb-utils amd64 7.7+5build4 [172 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-encodings all 1:1.0.5-0ubuntu2 [578 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-utils amd64 1:7.7+6build2 [94.6 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-base all 1:1.0.5 [5,896 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 xserver-common all 2:21.1.4-2ubuntu1.7~22.04.10 [28.5 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 xvfb amd64 2:21.1.4-2ubuntu1.7~22.04.10 [863 kB]\n",
            "Fetched 7,813 kB in 3s (2,779 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 9.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libfontenc1:amd64.\n",
            "(Reading database ... 122064 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libfontenc1_1%3a1.1.4-1build3_amd64.deb ...\n",
            "Unpacking libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Selecting previously unselected package libxfont2:amd64.\n",
            "Preparing to unpack .../1-libxfont2_1%3a2.0.5-1build1_amd64.deb ...\n",
            "Unpacking libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Selecting previously unselected package libxkbfile1:amd64.\n",
            "Preparing to unpack .../2-libxkbfile1_1%3a1.1.0-1build3_amd64.deb ...\n",
            "Unpacking libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Selecting previously unselected package x11-xkb-utils.\n",
            "Preparing to unpack .../3-x11-xkb-utils_7.7+5build4_amd64.deb ...\n",
            "Unpacking x11-xkb-utils (7.7+5build4) ...\n",
            "Selecting previously unselected package xfonts-encodings.\n",
            "Preparing to unpack .../4-xfonts-encodings_1%3a1.0.5-0ubuntu2_all.deb ...\n",
            "Unpacking xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Selecting previously unselected package xfonts-utils.\n",
            "Preparing to unpack .../5-xfonts-utils_1%3a7.7+6build2_amd64.deb ...\n",
            "Unpacking xfonts-utils (1:7.7+6build2) ...\n",
            "Selecting previously unselected package xfonts-base.\n",
            "Preparing to unpack .../6-xfonts-base_1%3a1.0.5_all.deb ...\n",
            "Unpacking xfonts-base (1:1.0.5) ...\n",
            "Selecting previously unselected package xserver-common.\n",
            "Preparing to unpack .../7-xserver-common_2%3a21.1.4-2ubuntu1.7~22.04.10_all.deb ...\n",
            "Unpacking xserver-common (2:21.1.4-2ubuntu1.7~22.04.10) ...\n",
            "Selecting previously unselected package xvfb.\n",
            "Preparing to unpack .../8-xvfb_2%3a21.1.4-2ubuntu1.7~22.04.10_amd64.deb ...\n",
            "Unpacking xvfb (2:21.1.4-2ubuntu1.7~22.04.10) ...\n",
            "Setting up libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Setting up xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Setting up libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Setting up libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Setting up x11-xkb-utils (7.7+5build4) ...\n",
            "Setting up xfonts-utils (1:7.7+6build2) ...\n",
            "Setting up xfonts-base (1:1.0.5) ...\n",
            "Setting up xserver-common (2:21.1.4-2ubuntu1.7~22.04.10) ...\n",
            "Setting up xvfb (2:21.1.4-2ubuntu1.7~22.04.10) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/relax\n",
        "import gym\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tqdm import tqdm\n",
        "from inspect import getsource\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "from relax.rl.actors import TD3, RandomUniform\n",
        "from relax.rl.critics import CDQN\n",
        "from relax.rl.models import DeltaEnvModel\n",
        "\n",
        "from relax.zoo.policies import DeterministicMLP\n",
        "from relax.zoo.critics import ContQMLP\n",
        "from relax.zoo.models import ContObsContAcsToObsMLP, ContObsContAcsToRewsMLP\n",
        "\n",
        "from relax.schedules import PiecewiseSchedule, LinearSchedule, CombinedSchedule\n",
        "from relax.exploration import RandomNormal\n",
        "\n",
        "from relax.data.sampling import Sampler\n",
        "from relax.data.replay_buffer import ReplayBuffer\n",
        "\n",
        "# from relax.gym.utils import visualize_actor\n",
        "from relax.gym.terminal_functions import walker2d_v2_terminal_fn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ut4EAT3fOfgv",
        "outputId": "a37a854c-668a-46b9-a4d6-229a3cbdb80b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/relax\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(obs_dim, acs_dim,\n",
        "              terminal_function,\n",
        "              ensemble_size=7):\n",
        "\n",
        "    obs_models = []\n",
        "    rews_models = []\n",
        "    for i in range(ensemble_size):\n",
        "        obs_models.append(\n",
        "            ContObsContAcsToObsMLP(input_obs_dim=obs_dim, output_obs_dim=obs_dim,\n",
        "                                   acs_dim=acs_dim, nunits=250, nlayers=2) #350 for ant\n",
        "        )\n",
        "        rews_models.append(\n",
        "            ContObsContAcsToRewsMLP(input_obs_dim=obs_dim, acs_dim=acs_dim,\n",
        "                                    nunits=250, nlayers=2)\n",
        "        )\n",
        "\n",
        "    # Creating schedules:\n",
        "    # first 5000 iterations no learning - just data collection\n",
        "    model_lr = PiecewiseSchedule({0: 5000}, 1e-3)\n",
        "\n",
        "    model = DeltaEnvModel(\n",
        "        obs_models=obs_models,\n",
        "        device=torch.device('cuda'),\n",
        "        learning_rate=model_lr,\n",
        "        noise=0.01,\n",
        "        batch_size=512,\n",
        "        rews_models=rews_models,\n",
        "        terminal_function=terminal_function,\n",
        "        n_steps_per_update=1,\n",
        "        update_freq=10,\n",
        "        stats_recalc_freq=500,\n",
        "        random_agg=False,\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "aR9UAGPLOqn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_actor_and_critic(obs_dim, acs_dim):\n",
        "\n",
        "    # Creating schedules:\n",
        "    # first 10000 iterations no learning - just data collection\n",
        "    policy_lr = PiecewiseSchedule({0: 10000}, 1e-3)\n",
        "    critic_lr = PiecewiseSchedule({0: 10000}, 1e-3)\n",
        "\n",
        "    schedule1 = PiecewiseSchedule({0.3: 10000}, 0.0)\n",
        "    schedule2 = LinearSchedule(0.1, 0, 1000000)\n",
        "    sigma_schedule = CombinedSchedule(schedule1, schedule2, max)\n",
        "\n",
        "    # Define exploration\n",
        "    exploration = RandomNormal(sigma=sigma_schedule,\n",
        "                               min_acs=-1.0,\n",
        "                               max_acs=1.0,\n",
        "                               n_random_steps=10000)\n",
        "\n",
        "    actor = TD3(\n",
        "        device=torch.device('cuda'),\n",
        "        mu_net=DeterministicMLP(obs_dim, acs_dim, out_activation=torch.nn.Tanh()),\n",
        "        learning_rate=policy_lr,\n",
        "        batch_size=100,\n",
        "        min_acs=-1.0,\n",
        "        max_acs=1.0,\n",
        "        exploration=exploration,\n",
        "    )\n",
        "\n",
        "    critic = CDQN(\n",
        "        critic_net=ContQMLP(obs_dim, acs_dim),\n",
        "        critic_net2=ContQMLP(obs_dim, acs_dim),\n",
        "        device=torch.device('cuda'),\n",
        "        learning_rate=critic_lr,\n",
        "        weight_decay=0.0\n",
        "    )\n",
        "\n",
        "    return actor, critic\n"
      ],
      "metadata": {
        "id": "sBPUdhWAOua_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env_name = 'Walker2d-v2'\n",
        "terminal_function = walker2d_v2_terminal_fn\n",
        "\n",
        "acs_dim = 6\n",
        "obs_dim = 17\n",
        "n_experiments = 4\n",
        "n_steps = 1000000"
      ],
      "metadata": {
        "id": "z22PLF9MO1VX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ..\n",
        "%cd relax_dyna_q_example"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_pLKU9IO5Qw",
        "outputId": "fa47e4ed-e1bf-4e87-b7da-f634f96bd31c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content/relax_dyna_q_example\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "actor, critic = get_actor_and_critic(obs_dim=obs_dim, acs_dim=acs_dim)\n",
        "\n",
        "# Model\n",
        "model = get_model(obs_dim=obs_dim, acs_dim=acs_dim,\n",
        "                  terminal_function=terminal_function,\n",
        "                  ensemble_size=7)\n",
        "\n",
        "# provide actor with critic\n",
        "actor.set_critic(critic)\n",
        "\n",
        "# setting the schedule for acceleration horizon\n",
        "horizon_schedule = PiecewiseSchedule({0: 20000}, 1)\n",
        "\n",
        "# provide actor with model for acceleration\n",
        "actor.set_acceleration(model=model,\n",
        "                       actor=RandomUniform(acs_dim=acs_dim,\n",
        "                                           min_acs=-1,\n",
        "                                           max_acs=1),\n",
        "                       h=horizon_schedule,\n",
        "                       tau=3.0,\n",
        "                       real_ratio=0.0,\n",
        "                       train_sampling=True)\n",
        "\n",
        "# Saving models:\n",
        "actor.load_checkpoint('trained_models/dyna_q_td3', 'dyna_q_td3_Walker2d-v2_experiment_2_actor')\n",
        "critic.load_checkpoint('trained_models/dyna_q_td3', 'dyna_q_td3_Walker2d-v2_experiment_2_critic')\n",
        "model.load_checkpoint('trained_models/dyna_q_td3', 'dyna_q_td3_Walker2d-v2_experiment_2_model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35zli2GNPDUJ",
        "outputId": "c9c42240-5526-48ce-8290-53fe677056ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded checkpoints for TD3...\n",
            "models_state_dict exploration_global_step global_step local_step n_updates n_target_updates optimizer n_policy_updates\n",
            "Loaded checkpoints for CDQN...\n",
            "models_state_dict global_step local_step n_updates n_target_updates optimizer optimizer2\n",
            "Loaded checkpoints for DeltaEnvModel...\n",
            "models_state_dict global_step local_step n_updates n_stats_updates n_model_resets updates_per_model obs_optimizer_0 obs_optimizer_1 obs_optimizer_2 obs_optimizer_3 obs_optimizer_4 obs_optimizer_5 obs_optimizer_6 rews_optimizer_0 rews_optimizer_1 rews_optimizer_2 rews_optimizer_3 rews_optimizer_4 rews_optimizer_5 rews_optimizer_6 buffer_stats\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env_name = 'Walker2d-v2'\n",
        "eval_env = gym.make(env_name)\n",
        "eval_env.seed(np.random.randint(100))\n",
        "eval_sampler = Sampler(env=eval_env)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qb-i2ZpkRBRN",
        "outputId": "ae793261-3497-411b-d523-f80c34826e29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:505: UserWarning: \u001b[33mWARN: The environment Walker2d-v2 is out of date. You should consider upgrading to version `v3` with the environment ID `Walker2d-v3`.\u001b[0m\n",
            "  logger.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Compiling /usr/local/lib/python3.10/dist-packages/mujoco_py/cymj.pyx because it changed.\n",
            "[1/1] Cythonizing /usr/local/lib/python3.10/dist-packages/mujoco_py/cymj.pyx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:running build_ext\n",
            "INFO:root:building 'mujoco_py.cymj' extension\n",
            "INFO:root:creating /usr/local/lib/python3.10/dist-packages/mujoco_py/generated/_pyxbld_2.0.2.13_310_linuxcpuextensionbuilder\n",
            "INFO:root:creating /usr/local/lib/python3.10/dist-packages/mujoco_py/generated/_pyxbld_2.0.2.13_310_linuxcpuextensionbuilder/temp.linux-x86_64-cpython-310\n",
            "INFO:root:creating /usr/local/lib/python3.10/dist-packages/mujoco_py/generated/_pyxbld_2.0.2.13_310_linuxcpuextensionbuilder/temp.linux-x86_64-cpython-310/usr\n",
            "INFO:root:creating /usr/local/lib/python3.10/dist-packages/mujoco_py/generated/_pyxbld_2.0.2.13_310_linuxcpuextensionbuilder/temp.linux-x86_64-cpython-310/usr/local\n",
            "INFO:root:creating /usr/local/lib/python3.10/dist-packages/mujoco_py/generated/_pyxbld_2.0.2.13_310_linuxcpuextensionbuilder/temp.linux-x86_64-cpython-310/usr/local/lib\n",
            "INFO:root:creating /usr/local/lib/python3.10/dist-packages/mujoco_py/generated/_pyxbld_2.0.2.13_310_linuxcpuextensionbuilder/temp.linux-x86_64-cpython-310/usr/local/lib/python3.10\n",
            "INFO:root:creating /usr/local/lib/python3.10/dist-packages/mujoco_py/generated/_pyxbld_2.0.2.13_310_linuxcpuextensionbuilder/temp.linux-x86_64-cpython-310/usr/local/lib/python3.10/dist-packages\n",
            "INFO:root:creating /usr/local/lib/python3.10/dist-packages/mujoco_py/generated/_pyxbld_2.0.2.13_310_linuxcpuextensionbuilder/temp.linux-x86_64-cpython-310/usr/local/lib/python3.10/dist-packages/mujoco_py\n",
            "INFO:root:creating /usr/local/lib/python3.10/dist-packages/mujoco_py/generated/_pyxbld_2.0.2.13_310_linuxcpuextensionbuilder/temp.linux-x86_64-cpython-310/usr/local/lib/python3.10/dist-packages/mujoco_py/gl\n",
            "INFO:root:x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.10/dist-packages/mujoco_py -I/usr/local/lib/python3.10/dist-packages/mujoco_py/binaries/linux/mujoco210/include -I/usr/local/lib/python3.10/dist-packages/numpy/core/include -I/usr/include/python3.10 -c /usr/local/lib/python3.10/dist-packages/mujoco_py/cymj.c -o /usr/local/lib/python3.10/dist-packages/mujoco_py/generated/_pyxbld_2.0.2.13_310_linuxcpuextensionbuilder/temp.linux-x86_64-cpython-310/usr/local/lib/python3.10/dist-packages/mujoco_py/cymj.o -fopenmp -w\n",
            "INFO:root:x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.10/dist-packages/mujoco_py -I/usr/local/lib/python3.10/dist-packages/mujoco_py/binaries/linux/mujoco210/include -I/usr/local/lib/python3.10/dist-packages/numpy/core/include -I/usr/include/python3.10 -c /usr/local/lib/python3.10/dist-packages/mujoco_py/gl/osmesashim.c -o /usr/local/lib/python3.10/dist-packages/mujoco_py/generated/_pyxbld_2.0.2.13_310_linuxcpuextensionbuilder/temp.linux-x86_64-cpython-310/usr/local/lib/python3.10/dist-packages/mujoco_py/gl/osmesashim.o -fopenmp -w\n",
            "INFO:root:creating /usr/local/lib/python3.10/dist-packages/mujoco_py/generated/_pyxbld_2.0.2.13_310_linuxcpuextensionbuilder/lib.linux-x86_64-cpython-310\n",
            "INFO:root:creating /usr/local/lib/python3.10/dist-packages/mujoco_py/generated/_pyxbld_2.0.2.13_310_linuxcpuextensionbuilder/lib.linux-x86_64-cpython-310/mujoco_py\n",
            "INFO:root:x86_64-linux-gnu-gcc -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 /usr/local/lib/python3.10/dist-packages/mujoco_py/generated/_pyxbld_2.0.2.13_310_linuxcpuextensionbuilder/temp.linux-x86_64-cpython-310/usr/local/lib/python3.10/dist-packages/mujoco_py/cymj.o /usr/local/lib/python3.10/dist-packages/mujoco_py/generated/_pyxbld_2.0.2.13_310_linuxcpuextensionbuilder/temp.linux-x86_64-cpython-310/usr/local/lib/python3.10/dist-packages/mujoco_py/gl/osmesashim.o -L/usr/local/lib/python3.10/dist-packages/mujoco_py/binaries/linux/mujoco210/bin -L/usr/lib/x86_64-linux-gnu -Wl,--enable-new-dtags,-R/usr/local/lib/python3.10/dist-packages/mujoco_py/binaries/linux/mujoco210/bin -lmujoco210 -lglewosmesa -lOSMesa -lGL -o /usr/local/lib/python3.10/dist-packages/mujoco_py/generated/_pyxbld_2.0.2.13_310_linuxcpuextensionbuilder/lib.linux-x86_64-cpython-310/mujoco_py/cymj.cpython-310-x86_64-linux-gnu.so -fopenmp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import io\n",
        "import base64\n",
        "import numpy as np\n",
        "\n",
        "from gym.wrappers import Monitor\n",
        "from gym import Wrapper\n",
        "from IPython.display import HTML\n",
        "from IPython import display as ipythondisplay\n",
        "from pyvirtualdisplay import Display\n",
        "\n",
        "from relax.data.sampling import Sampler\n",
        "\n"
      ],
      "metadata": {
        "id": "X13Xb6N1UC3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def wrap_env(env):\n",
        "    env = Monitor(env, 'content/video', force=True)\n",
        "    return env\n",
        "\n",
        "def show_video_func():\n",
        "    mp4list = glob.glob('content/video/*.mp4')\n",
        "    if len(mp4list) > 0:\n",
        "        mp4 = mp4list[0]\n",
        "        video = io.open(mp4, 'r+b').read()\n",
        "        encoded = base64.b64encode(video)\n",
        "        ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay\n",
        "                    loop controls style=\"height: 400px;\">\n",
        "                    <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "                 </video>'''.format(encoded.decode('ascii'))))\n",
        "    else:\n",
        "        print(\"Could not find video\")\n",
        "\n",
        "def set_random_initial_state(smp,incline_angle=0, case_number=1):\n",
        "    env = smp.env\n",
        "    env.reset()\n",
        "    # Assuming the environment is of type 'Walker2d-v3' with specific qpos and qvel attributes\n",
        "    qpos = env.env.sim.data.qpos\n",
        "    qvel = env.env.sim.data.qvel\n",
        "    # print(qpos)\n",
        "    # print(qvel)\n",
        "\n",
        "    if case_number == 1:\n",
        "      qpos[1:2] =  qpos[1:2]+ np.random.uniform(low=-0.005, high=0.005, size=1)  # Randomize root position (excluding x-axis)\n",
        "      qpos[2:] = qpos[2:] + np.random.uniform(low=-0.005, high=0.005, size=qpos[2:].shape)  # Randomize joint positions\n",
        "      qvel[:] = qvel[:] + np.random.uniform(low=-0.005, high=0.005, size=qvel.shape)  # Randomize velocities\n",
        "\n",
        "    if case_number == 2:\n",
        "      qpos[1:2] =  qpos[1:2]+ np.random.uniform(low=-0.05, high=0.05, size=1)  # Randomize root position (excluding x-axis)\n",
        "      qpos[2:] = qpos[2:] + np.random.uniform(low=-0.087, high=0.087, size=qpos[2:].shape)  # Randomize joint positions\n",
        "      qvel[:] = qvel[:] + np.random.uniform(low=-0.05, high=0.05, size=qvel.shape)  # Randomize velocities\n",
        "\n",
        "    if case_number == 3:\n",
        "      qpos[1:2] =  qpos[1:2]+ np.random.uniform(low=-0.1, high=0.1, size=1)  # Randomize root position (excluding x-axis)\n",
        "      qpos[2:] = qpos[2:] + np.random.uniform(low=-0.17, high=0.17, size=qpos[2:].shape)  # Randomize joint positions\n",
        "      qvel[:] = qvel[:] + np.random.uniform(low=-0.1, high=0.1, size=qvel.shape)  # Randomize velocities\n",
        "\n",
        "    if case_number == 4:\n",
        "      qpos[1:2] =  qpos[1:2]+ np.random.uniform(low=-0.15, high=0.15, size=1)  # Randomize root position (excluding x-axis)\n",
        "      qpos[2:] = qpos[2:] + np.random.uniform(low=-0.26, high=0.26, size=qpos[2:].shape)  # Randomize joint positions\n",
        "      qvel[:] = qvel[:] + np.random.uniform(low=-0.1, high=0.1, size=qvel.shape)  # Randomize velocities\n",
        "\n",
        "    # print(qpos)\n",
        "    # print(qvel)\n",
        "\n",
        "    # env.env.set_state(qpos, qvel)\n",
        "    ob = np.concatenate([qpos[1:], qvel])  # Exclude the first dimension (x-axis) of qpos\n",
        "    smp.add_obs(ob)\n",
        "\n",
        "    # Set the inclination of the plane\n",
        "    model = env.env.model\n",
        "    model.opt.gravity[0] = 9.81 * np.sin(incline_angle)  # Adjust gravity for inclination\n",
        "    model.opt.gravity[2] = -9.81 * np.cos(incline_angle)\n",
        "\n",
        "    return ob\n",
        "\n",
        "def apply_inclination_visual(frame, incline_angle):\n",
        "    \"\"\"\n",
        "    Apply visual indication of inclination to the frame.\n",
        "    This function adds a rotated rectangle or other visual markers to indicate the incline.\n",
        "    \"\"\"\n",
        "    import cv2\n",
        "    h, w, _ = frame.shape\n",
        "    overlay = frame.copy()\n",
        "    angle_degrees = np.degrees(incline_angle)\n",
        "\n",
        "    # Draw a tilted line or rectangle to indicate the incline\n",
        "    rect_center = (w // 2, h // 2)\n",
        "    rect_size = (w, h // 10)\n",
        "    rect = ((rect_center), rect_size, angle_degrees)\n",
        "\n",
        "    box = cv2.boxPoints(rect)\n",
        "    box = np.intp(box)  # Use np.intp instead of np.int0\n",
        "    cv2.drawContours(overlay, [box], 0, (0, 255, 0), -1)\n",
        "\n",
        "    # Blend the overlay with the original frame\n",
        "    alpha = 0.4  # Transparency factor\n",
        "    frame = cv2.addWeighted(overlay, alpha, frame, 1 - alpha, 0)\n",
        "\n",
        "    return frame"
      ],
      "metadata": {
        "id": "5-E_arhbUQd-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_env = wrap_env(eval_env)\n",
        "test_env.seed(0)\n",
        "\n",
        "obs_nlags = 0\n",
        "obs_concat_axis = -1\n",
        "obs_expand_axis = None\n",
        "obs_padding = 'first'\n",
        "\n",
        "if hasattr(actor, 'obs_nlags'):\n",
        "    obs_nlags = actor.obs_nlags\n",
        "if hasattr(actor, 'obs_concat_axis'):\n",
        "    obs_concat_axis = actor.obs_concat_axis\n",
        "if hasattr(actor, 'obs_expand_axis'):\n",
        "    obs_expand_axis = actor.obs_expand_axis\n",
        "if hasattr(actor, 'obs_padding'):\n",
        "    obs_padding = actor.obs_padding\n",
        "\n",
        "smp = Sampler(env=test_env,\n",
        "              obs_nlags=obs_nlags,\n",
        "              obs_concat_axis=obs_concat_axis,\n",
        "              obs_expand_axis=obs_expand_axis,\n",
        "              obs_padding=obs_padding)\n"
      ],
      "metadata": {
        "id": "ogr5XcOfUcRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_actor(actor, env, nsteps=200, size=(1400, 900), seed=0, train_sampling=False, data=None, incline_angle=0, case_number = 1, show_video=False, generate=True):\n",
        "    # display = Display(visible=0, size=size)\n",
        "    # display.start()\n",
        "\n",
        "    # test_env = wrap_env(env)\n",
        "    test_env.seed(seed)\n",
        "\n",
        "    # obs_nlags = getattr(actor, 'obs_nlags', 0)\n",
        "    # obs_concat_axis = getattr(actor, 'obs_concat_axis', -1)\n",
        "    # obs_expand_axis = getattr(actor, 'obs_expand_axis', None)\n",
        "    # obs_padding = getattr(actor, 'obs_padding', 'first')\n",
        "\n",
        "    # smp = Sampler(env=test_env, obs_nlags=obs_nlags, obs_concat_axis=obs_concat_axis, obs_expand_axis=obs_expand_axis, obs_padding=obs_padding)\n",
        "\n",
        "    # previous_mode = actor.train_sampling\n",
        "    # actor.train_sampling = train_sampling\n",
        "\n",
        "    ob = set_random_initial_state(smp, incline_angle=incline_angle,case_number=case_number)\n",
        "    if show_video:\n",
        "      frames = []\n",
        "\n",
        "    for i in range(nsteps):\n",
        "        if show_video:\n",
        "          frame = test_env.render(mode='rgb_array')\n",
        "          frames.append(frame)\n",
        "        smp.add_obs(ob)\n",
        "        _ob = smp.get_obs()\n",
        "        _ob = np.expand_dims(_ob, axis=0) # put _ob into batchmode for consistency\n",
        "        ac = actor.get_action(_ob)\n",
        "        ac = ac.squeeze(axis=0) # squeeze ac back for storage\n",
        "        if generate:\n",
        "            qpos = env.env.sim.data.qpos\n",
        "            qvel = env.env.sim.data.qvel\n",
        "            data[seed, i, :] = np.concatenate([qpos, qvel]) # 18 enteries\n",
        "\n",
        "        ob, rew, done, info = smp.step_env(ac)\n",
        "        # tot_rew += rew\n",
        "        # print(i)\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    test_env.close()\n",
        "    # actor.train_sampling = previous_mode\n",
        "    if show_video:\n",
        "        print('Loading video...')\n",
        "        for frame in frames:\n",
        "            plt.imshow(frame)\n",
        "            plt.axis('off')\n",
        "            plt.show()\n",
        "            ipythondisplay.clear_output(wait=True)\n",
        "        # show_video_fn()"
      ],
      "metadata": {
        "id": "AZj3ZZkZUe-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import IPython.display as ipythondisplay\n",
        "from moviepy.editor import ImageSequenceClip\n",
        "\n",
        "def visualize_data(actor, env, nsteps=200, size=(1400, 900), seed=0, train_sampling=False, data=None, incline_angle=0, show_video=False, generate=False):\n",
        "    display = Display(visible=0, size=size)\n",
        "    display.start()\n",
        "\n",
        "    test_env = wrap_env(env)\n",
        "    test_env.seed(seed)\n",
        "\n",
        "    obs_nlags = getattr(actor, 'obs_nlags', 0)\n",
        "    obs_concat_axis = getattr(actor, 'obs_concat_axis', -1)\n",
        "    obs_expand_axis = getattr(actor, 'obs_expand_axis', None)\n",
        "    obs_padding = getattr(actor, 'obs_padding', 'first')\n",
        "\n",
        "    smp = Sampler(env=test_env, obs_nlags=obs_nlags, obs_concat_axis=obs_concat_axis, obs_expand_axis=obs_expand_axis, obs_padding=obs_padding)\n",
        "\n",
        "    previous_mode = actor.train_sampling\n",
        "    actor.train_sampling = train_sampling\n",
        "\n",
        "    ob = test_env.reset()\n",
        "\n",
        "    tot_rew = 0\n",
        "    frames = []\n",
        "\n",
        "    for i in range(nsteps):\n",
        "      ob = data[i, :]\n",
        "      qpos = env.env.sim.data.qpos.copy()\n",
        "      qvel = env.env.sim.data.qvel.copy()\n",
        "\n",
        "      qpos[:] = data[i, :9]\n",
        "      qvel[:] = data[i, 9:]\n",
        "      env.env.set_state(qpos, qvel)\n",
        "\n",
        "      frame = test_env.render(mode='rgb_array')\n",
        "      frames.append(frame)\n",
        "\n",
        "    test_env.close()\n",
        "    actor.train_sampling = previous_mode\n",
        "    if show_video:\n",
        "        print('Loading video...')\n",
        "        for frame in frames:\n",
        "            plt.imshow(frame)\n",
        "            plt.axis('off')\n",
        "            plt.show()\n",
        "            ipythondisplay.clear_output(wait=True)\n",
        "        clip = ImageSequenceClip(frames, fps=30)\n",
        "        clip.write_videofile(f\"/content/walker_trajectory{seed}.mp4\")\n",
        "        print(\"Video saved successfully.\")"
      ],
      "metadata": {
        "id": "DZdgp7f5UfyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To visualize the generated data:\n",
        "loaded_data = torch.load('/content/Latent_ODE_ECE_228/data/HopperPhysics/training.pt')\n",
        "visualize_data(actor=actor, env=eval_env, nsteps=100, train_sampling=False, data=loaded_data[100], seed=0, incline_angle=0, show_video=True, generate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "bJoldPmwU0mP",
        "outputId": "92f814c9-9b67-4670-ca90-1f37521d3ebd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/lib/python3.10/subprocess.py:1796: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = _posixsubprocess.fork_exec(\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "could not broadcast input array from shape (5,) into shape (9,)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-d452a1fbaf73>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# To visualize the generated data:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mloaded_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/Latent_ODE_ECE_228/data/HopperPhysics/training.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mvisualize_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mactor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_env\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnsteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_sampling\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloaded_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincline_angle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_video\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-16-ac4097bc85aa>\u001b[0m in \u001b[0;36mvisualize_data\u001b[0;34m(actor, env, nsteps, size, seed, train_sampling, data, incline_angle, show_video, generate)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m       \u001b[0mqpos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m       \u001b[0mqvel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m       \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqvel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (5,) into shape (9,)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s75yncRAKb7o",
        "outputId": "960a9510-1bf4-4da3-eec0-a4ffb13927af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/relax_dyna_q_example\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ..\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzxNL7oRam2t",
        "outputId": "4632a61e-0a0b-4ce1-a2ed-14ed19e8bdc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Latent_ODE_ECE_228/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfKGRyBLaq6M",
        "outputId": "66d88fff-9daa-415f-9553-7f1f892f548f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Latent_ODE_ECE_228\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install torchdiffeq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8V-Y9tDbKquK",
        "outputId": "5700d777-18a5-4bfa-e621-c009117d2260"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchdiffeq\n",
            "  Downloading torchdiffeq-0.2.4-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from torchdiffeq) (2.3.0+cu121)\n",
            "Requirement already satisfied: scipy>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from torchdiffeq) (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy>=1.4.0->torchdiffeq) (1.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (4.12.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.5.0->torchdiffeq) (12.5.40)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.5.0->torchdiffeq) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.5.0->torchdiffeq) (1.3.0)\n",
            "Installing collected packages: torchdiffeq\n",
            "Successfully installed torchdiffeq-0.2.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwvprimRNRCm",
        "outputId": "cb11b9cc-434c-4c83-df73-df1010537dfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Latent_ODE_ECE_228\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "from torch.distributions.normal import Normal\n",
        "import numpy as np\n",
        "import time\n",
        "from random import SystemRandom\n",
        "\n",
        "import lib.utils as utils\n",
        "from lib.create_latent_ode_model import create_LatentODE_model\n",
        "from lib.utils import compute_loss_all_batches, get_next_batch, makedirs, get_logger\n",
        "\n",
        "from lib.rnn_baselines import *\n",
        "from lib.ode_rnn import *\n",
        "from lib.create_latent_ode_model import create_LatentODE_model\n",
        "from lib.parse_datasets import parse_datasets\n",
        "from lib.ode_func import ODEFunc, ODEFunc_w_Poisson\n",
        "from lib.diffeq_solver import DiffeqSolver\n",
        "from mujoco_physics import HopperPhysics\n",
        "from lib.latent_ode import LatentODE\n",
        "\n"
      ],
      "metadata": {
        "id": "ArN7oLd3fZ9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZK02i_Bff2n",
        "outputId": "a2f976d4-4321-45a4-d599-81df488ab61f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Args:\n",
        "    def __init__(self, **kwargs):\n",
        "        self.__dict__.update(kwargs)"
      ],
      "metadata": {
        "id": "X1O72t-Mfhtv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args = Args(\n",
        "    n=10000,  # Size of the dataset\n",
        "    niters=100,\n",
        "    lr=1e-2,  # Starting learning rate\n",
        "    batch_size=50,\n",
        "    viz=False,  # Show plots while training\n",
        "    save='experiments/',  # Path to save checkpoints\n",
        "    load=None,  # ID of the experiment to load for evaluation. If None, run a new experiment\n",
        "    random_seed=1991,  # Random seed\n",
        "    dataset='hopper',  # Dataset to load\n",
        "    sample_tp=0.5,  # Number of time points to sub-sample\n",
        "    cut_tp=None,  # Cut out the section of the timeline\n",
        "    quantization=0.1,  # Quantization on the physionet dataset\n",
        "    latent_ode=False,  # Run Latent ODE seq2seq model\n",
        "    z0_encoder='odernn',  # Type of encoder for Latent ODE model\n",
        "    classic_rnn=False,  # Run RNN baseline\n",
        "    rnn_cell=\"expdecay\",  # RNN Cell type #gru, expdecay- gru-d\n",
        "    input_decay=True,  # For RNN: use the input that is the weighted average of empirical mean and previous value\n",
        "    ode_rnn=True,  # Run ODE-RNN baseline\n",
        "    rnn_vae=False,  # Run RNN baseline: seq2seq model with sampling of the h0 and ELBO loss\n",
        "    latents=24,  # Size of the latent state\n",
        "    rec_dims=30,  # Dimensionality of the recognition model\n",
        "    rec_layers=3,  # Number of layers in ODE func in recognition ODE\n",
        "    gen_layers=3,  # Number of layers in ODE func in generative ODE\n",
        "    units=300,  # Number of units per layer in ODE func\n",
        "    gru_units=100,  # Number of units per layer in each of GRU update networks\n",
        "    poisson=False,  # Model poisson-process likelihood for the density of events in addition to reconstruction\n",
        "    classif=False,  # Include binary classification loss\n",
        "    linear_classif=False,  # Use a linear classifier instead of 1-layer NN\n",
        "    extrap=False,  # Set extrapolation mode\n",
        "    timepoints=100,  # Total number of time-points\n",
        "    max_t=5.0,  # Subsample points in the interval [0, args.max_t]\n",
        "    noise_weight=0.01  # Noise amplitude for generated trajectories\n",
        ")\n"
      ],
      "metadata": {
        "id": "63eXSvhJfk25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(args.random_seed)\n",
        "np.random.seed(args.random_seed)\n",
        "\n",
        "experimentID = args.load\n",
        "if experimentID is None:\n",
        "\t# Make a new experiment ID\n",
        "\texperimentID = int(SystemRandom().random()*100000)\n",
        "ckpt_path = os.path.join(args.save, \"experiment_\" + str(experimentID) + '.ckpt')\n",
        "\n",
        "start = time.time()\n",
        "print(\"Sampling dataset of {} training examples\".format(args.n))\n",
        "\n",
        "input_command = f\"run_models.py --n {args.n} --niters {args.niters} --lr {args.lr} --batch_size {args.batch_size} \" \\\n",
        "                f\"--viz {args.viz} --save {args.save} --random_seed {args.random_seed} --dataset {args.dataset} \" \\\n",
        "                f\"--latent_ode {args.latent_ode} --classic_rnn {args.classic_rnn} --ode_rnn {args.ode_rnn}--z0_encoder {args.z0_encoder} --latents {args.latents} \" \\\n",
        "                f\"--rec_dims {args.rec_dims} --rec_layers {args.rec_layers} --gen_layers {args.gen_layers} \" \\\n",
        "                f\"--units {args.units} --gru_units {args.gru_units} --timepoints {args.timepoints} --max_t {args.max_t} \" \\\n",
        "                f\"--noise_weight {args.noise_weight} --extrap {args.extrap} \"\n",
        "\n",
        "if args.load:\n",
        "\tinput_command += f\" --load {args.load}\"\n",
        "\n",
        "makedirs(\"results/\")\n",
        "\n",
        "print(f\"Checkpoint path: {ckpt_path}\")\n",
        "print(f\"Time taken for setup: {time.time() - start} seconds\")\n",
        "print(f\"Input command: {input_command}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Gej5E8lflzc",
        "outputId": "dca8bf87-a93b-45ac-e342-176ac2900469"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sampling dataset of 10000 training examples\n",
            "Checkpoint path: experiments/experiment_4669.ckpt\n",
            "Time taken for setup: 0.004057884216308594 seconds\n",
            "Input command: run_models.py --n 10000 --niters 100 --lr 0.01 --batch_size 50 --viz False --save experiments/ --random_seed 1991 --dataset hopper --latent_ode True --classic_rnn False --ode_rnn False--z0_encoder odernn --latents 24 --rec_dims 30 --rec_layers 3 --gen_layers 3 --units 300 --gru_units 100 --timepoints 100 --max_t 5.0 --noise_weight 0.01 --extrap False \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_obj = parse_datasets(args, device)\n",
        "input_dim = data_obj[\"input_dim\"]\n",
        "\n",
        "print(f\"Input dimension: {input_dim}\")\n",
        "\n",
        "classif_per_tp = False\n",
        "if (\"classif_per_tp\" in data_obj):\n",
        "\t\t# do classification per time point rather than on a time series as a whole\n",
        "\t\tclassif_per_tp = data_obj[\"classif_per_tp\"]\n",
        "\n",
        "if args.classif and (args.dataset == \"hopper\" or args.dataset == \"periodic\"):\n",
        "\t\traise Exception(\"Classification task is not available for MuJoCo and 1d datasets\")\n",
        "\n",
        "n_labels = 1\n",
        "if args.classif:\n",
        "\tif (\"n_labels\" in data_obj):\n",
        "\t\tn_labels = data_obj[\"n_labels\"]\n",
        "\telse:\n",
        "\t\traise Exception(\"Please provide number of labels for classification task\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6X24YECfnwR",
        "outputId": "28504eac-6bd2-4216-a287-c5502c10c5c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input dimension: 18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "obsrv_std = 1e-3\n",
        "obsrv_std = torch.Tensor([obsrv_std]).to(device)\n",
        "z0_prior = Normal(torch.Tensor([0.0]).to(device), torch.Tensor([1.]).to(device))"
      ],
      "metadata": {
        "id": "Lo0UihDifqCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if args.rnn_vae:\n",
        "\t\tif args.poisson:\n",
        "\t\t\tprint(\"Poisson process likelihood not implemented for RNN-VAE: ignoring --poisson\")\n",
        "\n",
        "\t\t# Create RNN-VAE model\n",
        "\t\tmodel = RNN_VAE(input_dim, args.latents,\n",
        "\t\t\tdevice = device,\n",
        "\t\t\trec_dims = args.rec_dims,\n",
        "\t\t\tconcat_mask = True,\n",
        "\t\t\tobsrv_std = obsrv_std,\n",
        "\t\t\tz0_prior = z0_prior,\n",
        "\t\t\tuse_binary_classif = args.classif,\n",
        "\t\t\tclassif_per_tp = classif_per_tp,\n",
        "\t\t\tlinear_classifier = args.linear_classif,\n",
        "\t\t\tn_units = args.units,\n",
        "\t\t\tinput_space_decay = args.input_decay,\n",
        "\t\t\tcell = args.rnn_cell,\n",
        "\t\t\tn_labels = n_labels,\n",
        "\t\t\ttrain_classif_w_reconstr = (args.dataset == \"physionet\")\n",
        "\t\t\t).to(device)\n",
        "elif args.classic_rnn:\n",
        "\t\tif args.poisson:\n",
        "\t\t\tprint(\"Poisson process likelihood not implemented for RNN: ignoring --poisson\")\n",
        "\n",
        "\t\tif args.extrap:\n",
        "\t\t\traise Exception(\"Extrapolation for standard RNN not implemented\")\n",
        "\t\t# Create RNN model\n",
        "\t\tmodel = Classic_RNN(input_dim, args.latents, device,\n",
        "\t\t\tconcat_mask = True, obsrv_std = obsrv_std,\n",
        "\t\t\tn_units = args.units,\n",
        "\t\t\tuse_binary_classif = args.classif,\n",
        "\t\t\tclassif_per_tp = classif_per_tp,\n",
        "\t\t\tlinear_classifier = args.linear_classif,\n",
        "\t\t\tinput_space_decay = args.input_decay,\n",
        "\t\t\tcell = args.rnn_cell,\n",
        "\t\t\tn_labels = n_labels,\n",
        "\t\t\ttrain_classif_w_reconstr = (args.dataset == \"physionet\")\n",
        "\t\t\t).to(device)\n",
        "elif args.ode_rnn:\n",
        "\t\t# Create ODE-GRU model\n",
        "\t\tn_ode_gru_dims = args.latents\n",
        "\n",
        "\t\tif args.poisson:\n",
        "\t\t\tprint(\"Poisson process likelihood not implemented for ODE-RNN: ignoring --poisson\")\n",
        "\n",
        "\t\tif args.extrap:\n",
        "\t\t\traise Exception(\"Extrapolation for ODE-RNN not implemented\")\n",
        "\n",
        "\t\tode_func_net = utils.create_net(n_ode_gru_dims, n_ode_gru_dims,\n",
        "\t\t\tn_layers = args.rec_layers, n_units = args.units, nonlinear = nn.Tanh)\n",
        "\n",
        "\t\trec_ode_func = ODEFunc(\n",
        "\t\t\tinput_dim = input_dim,\n",
        "\t\t\tlatent_dim = n_ode_gru_dims,\n",
        "\t\t\tode_func_net = ode_func_net,\n",
        "\t\t\tdevice = device).to(device)\n",
        "\n",
        "\t\tz0_diffeq_solver = DiffeqSolver(input_dim, rec_ode_func, \"euler\", args.latents,\n",
        "\t\t\todeint_rtol = 1e-3, odeint_atol = 1e-4, device = device)\n",
        "\n",
        "\t\tmodel = ODE_RNN(input_dim, n_ode_gru_dims, device = device,\n",
        "\t\t\tz0_diffeq_solver = z0_diffeq_solver, n_gru_units = args.gru_units,\n",
        "\t\t\tconcat_mask = True, obsrv_std = obsrv_std,\n",
        "\t\t\tuse_binary_classif = args.classif,\n",
        "\t\t\tclassif_per_tp = classif_per_tp,\n",
        "\t\t\tn_labels = n_labels,\n",
        "\t\t\ttrain_classif_w_reconstr = (args.dataset == \"physionet\")\n",
        "\t\t\t).to(device)\n",
        "elif args.latent_ode:\n",
        "\t\tmodel = create_LatentODE_model(args, input_dim, z0_prior, obsrv_std, device,\n",
        "\t\t\tclassif_per_tp = classif_per_tp,\n",
        "\t\t\tn_labels = n_labels)\n",
        "else:\n",
        "\traise Exception(\"Model not specified\")"
      ],
      "metadata": {
        "id": "FfkoWKKJftky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ckpt_path=r\"/content/experiment_latents_24_ODE_RNN_0.5.ckpt\""
      ],
      "metadata": {
        "id": "20pCi_rKfzHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "utils.get_ckpt_model(ckpt_path, model, device)"
      ],
      "metadata": {
        "id": "RJM-35ozgnrr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dict = utils.get_next_batch(data_obj[\"test_dataloader\"])"
      ],
      "metadata": {
        "id": "5P1nQzl7hLxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data =  test_dict[\"data_to_predict\"]\n",
        "time_steps = test_dict[\"tp_to_predict\"]\n",
        "mask = test_dict[\"mask_predicted_data\"]\n",
        "\n",
        "observed_data =  test_dict[\"observed_data\"]\n",
        "observed_time_steps = test_dict[\"observed_tp\"]\n",
        "observed_mask = test_dict[\"observed_mask\"]\n",
        "\n",
        "device = utils.get_device(time_steps)\n",
        "\n",
        "time_steps_to_predict = time_steps\n",
        "\n",
        "\n",
        "if isinstance(model, LatentODE):\n",
        "\t# sample at the original time points\n",
        "\ttime_steps_to_predict = utils.linspace_vector(time_steps[0], time_steps[-1], 100).to(device)\n",
        "\n",
        "reconstructions, info = model.get_reconstruction(time_steps_to_predict,\n",
        "\tobserved_data, observed_time_steps, mask = observed_mask, n_traj_samples = 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gx_t2wmbhNCC",
        "outputId": "bb4d65ac-41b8-4efd-b2a7-89609cb89be7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/torchdiffeq/_impl/misc.py:306: UserWarning: t is not on the same device as y0. Coercing to y0.device.\n",
            "  warnings.warn(\"t is not on the same device as y0. Coercing to y0.device.\")\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_data[100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zg9DkzNuo1O6",
        "outputId": "289380b7-f2d8-47f1-b799-ada8e797d5bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 4.72591248e-03,  1.25508480e+00, -1.24619654e-03, ...,\n",
              "         1.56703646e-03,  1.48397823e-04, -6.08339647e-03],\n",
              "       [ 1.84401745e-03,  1.25302162e+00, -4.00697002e-02, ...,\n",
              "        -1.16198611e+01,  4.80388625e-01,  1.65958729e+01],\n",
              "       [-3.94614163e-03,  1.24632826e+00, -1.16791526e-01, ...,\n",
              "        -1.13233929e+01,  4.29998500e-01,  3.15696615e+01],\n",
              "       ...,\n",
              "       [ 4.36743418e+00,  1.12175382e+00,  7.47254487e-01, ...,\n",
              "        -4.05885032e-01,  1.04069116e-01, -2.28577027e+01],\n",
              "       [ 4.39975970e+00,  1.13012849e+00,  7.45734361e-01, ...,\n",
              "        -3.63658583e-01, -1.42319016e-01, -9.58894256e+00],\n",
              "       [ 4.43165782e+00,  1.13643772e+00,  7.46991339e-01, ...,\n",
              "        -2.47505941e-01, -1.14007117e-01, -5.64384175e+00]])"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "observed_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1nuTvbBhQhv",
        "outputId": "a59c65ce-ad15-4b1d-fbd2-cfc3945e6c17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2000, 100, 18])"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reconstructions.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCMJ5otmhl4E",
        "outputId": "9bbc364b-5dc0-4682-d873-b0bce25f1603"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 2000, 100, 18])"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reconstructions.mean(dim=0).detach()[91]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYf-VhIPhmxI",
        "outputId": "52cb04d6-e5fe-44b4-c8a6-cccaaff6ab59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2411, 0.6016, 1.7056,  ..., 0.6817, 0.5410, 1.2936],\n",
              "        [0.2296, 0.6228, 1.6483,  ..., 0.6949, 0.5696, 1.2935],\n",
              "        [0.2741, 0.6425, 1.6935,  ..., 0.6722, 0.5308, 1.2834],\n",
              "        ...,\n",
              "        [0.4834, 0.6834, 1.7255,  ..., 0.6344, 0.5093, 1.3527],\n",
              "        [0.4905, 0.6856, 1.6988,  ..., 0.6496, 0.4664, 1.3366],\n",
              "        [0.5001, 0.6904, 1.6767,  ..., 0.6664, 0.4184, 1.3239]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reconstructions.mean(dim=0).detach()[81]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C90zQ547nlgR",
        "outputId": "fea916d1-feee-44dd-bedb-51dc13eb1669"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1239, 0.6942, 0.0754,  ..., 0.6740, 0.5338, 1.2816],\n",
              "        [0.1252, 0.6950, 0.0911,  ..., 0.6514, 0.5447, 1.3209],\n",
              "        [0.1281, 0.7367, 0.0340,  ..., 0.6611, 0.5209, 1.2865],\n",
              "        ...,\n",
              "        [0.3489, 0.6498, 1.6012,  ..., 0.6795, 0.5859, 1.1961],\n",
              "        [0.3513, 0.6443, 1.6183,  ..., 0.6773, 0.5789, 1.1816],\n",
              "        [0.3518, 0.6409, 1.6378,  ..., 0.6757, 0.5722, 1.1863]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_data(actor=actor, env=eval_env, nsteps=100, train_sampling=False, data=observed_data[91].cpu(), seed=0, incline_angle=0, show_video=True, generate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkycbLiLhpiF",
        "outputId": "81f1652d-a9a5-4967-a10a-54e37851711e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Building video /content/walker_trajectory0.mp4.\n",
            "Moviepy - Writing video /content/walker_trajectory0.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready /content/walker_trajectory0.mp4\n",
            "Video saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_data(actor=actor, env=eval_env, nsteps=100, train_sampling=False, data=reconstructions.mean(dim=0)[91].cpu().detach(), seed=0, incline_angle=0, show_video=True, generate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "te_UNzyIjJw9",
        "outputId": "66bc57a0-297c-44ad-c1bf-784c8ef9cfbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Building video /content/walker_trajectory0.mp4.\n",
            "Moviepy - Writing video /content/walker_trajectory0.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready /content/walker_trajectory0.mp4\n",
            "Video saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GT Render\n"
      ],
      "metadata": {
        "id": "o4H2cO7qwkf3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args = Args(\n",
        "    n=10000,  # Size of the dataset\n",
        "    niters=100,\n",
        "    lr=1e-2,  # Starting learning rate\n",
        "    batch_size=50,\n",
        "    viz=False,  # Show plots while training\n",
        "    save='experiments/',  # Path to save checkpoints\n",
        "    load=None,  # ID of the experiment to load for evaluation. If None, run a new experiment\n",
        "    random_seed=1991,  # Random seed\n",
        "    dataset='hopper',  # Dataset to load\n",
        "    sample_tp=None,  # Number of time points to sub-sample\n",
        "    cut_tp=None,  # Cut out the section of the timeline\n",
        "    quantization=0.1,  # Quantization on the physionet dataset\n",
        "    latent_ode=True,  # Run Latent ODE seq2seq model\n",
        "    z0_encoder='odernn',  # Type of encoder for Latent ODE model\n",
        "    classic_rnn=False,  # Run RNN baseline\n",
        "    rnn_cell=\"expdecay\",  # RNN Cell type #gru, expdecay- gru-d\n",
        "    input_decay=True,  # For RNN: use the input that is the weighted average of empirical mean and previous value\n",
        "    ode_rnn=False,  # Run ODE-RNN baseline\n",
        "    rnn_vae=False,  # Run RNN baseline: seq2seq model with sampling of the h0 and ELBO loss\n",
        "    latents=15,  # Size of the latent state\n",
        "    rec_dims=30,  # Dimensionality of the recognition model\n",
        "    rec_layers=3,  # Number of layers in ODE func in recognition ODE\n",
        "    gen_layers=3,  # Number of layers in ODE func in generative ODE\n",
        "    units=300,  # Number of units per layer in ODE func\n",
        "    gru_units=100,  # Number of units per layer in each of GRU update networks\n",
        "    poisson=False,  # Model poisson-process likelihood for the density of events in addition to reconstruction\n",
        "    classif=False,  # Include binary classification loss\n",
        "    linear_classif=False,  # Use a linear classifier instead of 1-layer NN\n",
        "    extrap=False,  # Set extrapolation mode\n",
        "    timepoints=100,  # Total number of time-points\n",
        "    max_t=5.0,  # Subsample points in the interval [0, args.max_t]\n",
        "    noise_weight=0.01  # Noise amplitude for generated trajectories\n",
        ")\n"
      ],
      "metadata": {
        "id": "9lMiVv5guizU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if args.rnn_vae:\n",
        "\t\tif args.poisson:\n",
        "\t\t\tprint(\"Poisson process likelihood not implemented for RNN-VAE: ignoring --poisson\")\n",
        "\n",
        "\t\t# Create RNN-VAE model\n",
        "\t\tmodel = RNN_VAE(input_dim, args.latents,\n",
        "\t\t\tdevice = device,\n",
        "\t\t\trec_dims = args.rec_dims,\n",
        "\t\t\tconcat_mask = True,\n",
        "\t\t\tobsrv_std = obsrv_std,\n",
        "\t\t\tz0_prior = z0_prior,\n",
        "\t\t\tuse_binary_classif = args.classif,\n",
        "\t\t\tclassif_per_tp = classif_per_tp,\n",
        "\t\t\tlinear_classifier = args.linear_classif,\n",
        "\t\t\tn_units = args.units,\n",
        "\t\t\tinput_space_decay = args.input_decay,\n",
        "\t\t\tcell = args.rnn_cell,\n",
        "\t\t\tn_labels = n_labels,\n",
        "\t\t\ttrain_classif_w_reconstr = (args.dataset == \"physionet\")\n",
        "\t\t\t).to(device)\n",
        "elif args.classic_rnn:\n",
        "\t\tif args.poisson:\n",
        "\t\t\tprint(\"Poisson process likelihood not implemented for RNN: ignoring --poisson\")\n",
        "\n",
        "\t\tif args.extrap:\n",
        "\t\t\traise Exception(\"Extrapolation for standard RNN not implemented\")\n",
        "\t\t# Create RNN model\n",
        "\t\tmodel = Classic_RNN(input_dim, args.latents, device,\n",
        "\t\t\tconcat_mask = True, obsrv_std = obsrv_std,\n",
        "\t\t\tn_units = args.units,\n",
        "\t\t\tuse_binary_classif = args.classif,\n",
        "\t\t\tclassif_per_tp = classif_per_tp,\n",
        "\t\t\tlinear_classifier = args.linear_classif,\n",
        "\t\t\tinput_space_decay = args.input_decay,\n",
        "\t\t\tcell = args.rnn_cell,\n",
        "\t\t\tn_labels = n_labels,\n",
        "\t\t\ttrain_classif_w_reconstr = (args.dataset == \"physionet\")\n",
        "\t\t\t).to(device)\n",
        "elif args.ode_rnn:\n",
        "\t\t# Create ODE-GRU model\n",
        "\t\tn_ode_gru_dims = args.latents\n",
        "\n",
        "\t\tif args.poisson:\n",
        "\t\t\tprint(\"Poisson process likelihood not implemented for ODE-RNN: ignoring --poisson\")\n",
        "\n",
        "\t\tif args.extrap:\n",
        "\t\t\traise Exception(\"Extrapolation for ODE-RNN not implemented\")\n",
        "\n",
        "\t\tode_func_net = utils.create_net(n_ode_gru_dims, n_ode_gru_dims,\n",
        "\t\t\tn_layers = args.rec_layers, n_units = args.units, nonlinear = nn.Tanh)\n",
        "\n",
        "\t\trec_ode_func = ODEFunc(\n",
        "\t\t\tinput_dim = input_dim,\n",
        "\t\t\tlatent_dim = n_ode_gru_dims,\n",
        "\t\t\tode_func_net = ode_func_net,\n",
        "\t\t\tdevice = device).to(device)\n",
        "\n",
        "\t\tz0_diffeq_solver = DiffeqSolver(input_dim, rec_ode_func, \"euler\", args.latents,\n",
        "\t\t\todeint_rtol = 1e-3, odeint_atol = 1e-4, device = device)\n",
        "\n",
        "\t\tmodel = ODE_RNN(input_dim, n_ode_gru_dims, device = device,\n",
        "\t\t\tz0_diffeq_solver = z0_diffeq_solver, n_gru_units = args.gru_units,\n",
        "\t\t\tconcat_mask = True, obsrv_std = obsrv_std,\n",
        "\t\t\tuse_binary_classif = args.classif,\n",
        "\t\t\tclassif_per_tp = classif_per_tp,\n",
        "\t\t\tn_labels = n_labels,\n",
        "\t\t\ttrain_classif_w_reconstr = (args.dataset == \"physionet\")\n",
        "\t\t\t).to(device)\n",
        "elif args.latent_ode:\n",
        "\t\tmodel = create_LatentODE_model(args, input_dim, z0_prior, obsrv_std, device,\n",
        "\t\t\tclassif_per_tp = classif_per_tp,\n",
        "\t\t\tn_labels = n_labels)\n",
        "else:\n",
        "\traise Exception(\"Model not specified\")"
      ],
      "metadata": {
        "id": "kn0cO35LwwDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_obj = parse_datasets(args, device)\n"
      ],
      "metadata": {
        "id": "-F9gtLuCwxLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ckpt_path=  r\"/content/Latent_ODE_ECE_228/experiments/experiment_10006.ckpt\""
      ],
      "metadata": {
        "id": "dHtr9132w0Fc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "utils.get_ckpt_model(ckpt_path, model, device)"
      ],
      "metadata": {
        "id": "oUmHbmH6w2GB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dict = utils.get_next_batch(data_obj[\"test_dataloader\"])"
      ],
      "metadata": {
        "id": "VJ1Mkpoew3HZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data =  test_dict[\"data_to_predict\"]\n",
        "time_steps = test_dict[\"tp_to_predict\"]\n",
        "mask = test_dict[\"mask_predicted_data\"]\n",
        "\n",
        "observed_data =  test_dict[\"observed_data\"]\n",
        "observed_time_steps = test_dict[\"observed_tp\"]\n",
        "observed_mask = test_dict[\"observed_mask\"]\n",
        "\n",
        "device = utils.get_device(time_steps)\n",
        "\n",
        "time_steps_to_predict = time_steps\n",
        "\n",
        "\n",
        "if isinstance(model, LatentODE):\n",
        "\t# sample at the original time points\n",
        "\ttime_steps_to_predict = utils.linspace_vector(time_steps[0], time_steps[-1], 100).to(device)\n",
        "\n",
        "reconstructions, info = model.get_reconstruction(time_steps_to_predict,\n",
        "\tobserved_data, observed_time_steps, mask = observed_mask, n_traj_samples = 10)"
      ],
      "metadata": {
        "id": "ruO68PSow41r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "traj_index=350\n",
        "percentage=str(args.sample_tp)\n",
        "model=model.__class__.__name__"
      ],
      "metadata": {
        "id": "XyK1Y1Nxw6p8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir= f\"gt_render_{traj_index}_{percentage}_{model}\"\n",
        "hopper = HopperPhysics(root='data', download=False, generate=False)\n",
        "hopper.visualize(observed_data[traj_index], plot_name=f'traj_{traj_index}', dirname=output_dir)\n",
        "output_vid_gt=f\"{output_dir}/ground_truth.mp4\"\n",
        "frames_to_video(output_dir,output_vid_gt)"
      ],
      "metadata": {
        "id": "82K9WWwWw885"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}